"""
This script generates a list of elements that will be used to filter the words from a splitted UTE that are 'generic'. The idea is to remove those words that are too common and do not define the company. The list is generated by taking the elements that appear in more than 95% of the UTEs. Then, some additional elements are added manually. The final list is saved in a file.

Author: Lorena Calvo-Bartolomé
Date: 15/02/2024
"""
import argparse
import pathlib
from collections import Counter

import numpy as np
import pandas as pd


def flatten(xss):
    """Flatten a list of lists into a single list.
    """
    return [x for xs in xss for x in xs]


MANUAL_STOPS = [
    "UTE", "ute", "u.t.e.", "servicio", "servicios", "obras",
    "fundación", "información", "técnica", "proyectos", "y",
    "engineering", "architecture", "technology", "solutions", "infraestructuras", "inst", "contrucciones", "construccions", "office", "spain", "associacio", "formacio", "arquitectes", "gestio", "information", "international", "systems", "system", "excavacions", "facility", "partners", "consulting", "catalunya", "constr", "projects", "intelligence", "educatio", "systems", "electrodomesticos", "marketing", "extremadura", "networks", "estacionamientos", "management", "gipuzkoa", "coslada", "security", "project", "design", "studio", "security", "service", "avda", "serv", "trans", "quality", "group", "services", "asturias", "manteniments", "investment", "quality", "cantabria", "medioambientales", "sist", "energy", "rehabilitaciones", "bizkaia", "research", "enginyeria", "electronics", "solucions", "facilities", "music", "technologies", "portugalete"
]


def main():

    parser = argparse.ArgumentParser()
    parser.add_argument("--path_data", type=str,
                        help="Path to the data folder.",
                        default="../data")
    parser.add_argument("--utes", type=str,
                        help="Name of the file with the utes.",
                        default="utes_spark_stops.parquet")

    args = parser.parse_args()

    # Load the data
    path_data = pathlib.Path(args.path_data)
    path_resolved = path_data.joinpath(args.utes)
    df = pd.read_parquet(path_resolved)

    # Generate a list with the UTES "splits"
    df["len"] = df.utes.apply(len)
    splits_list = df[df.len > 0]['splits'].values.tolist()
    splits_list = flatten(splits_list)

    # Count the frequency of each element
    frequency_counter = Counter(splits_list)
    upper_limit = 95
    per_upper = np.percentile(list(frequency_counter.values()), upper_limit)

    print(f"-- -- Upper limit: {per_upper}")

    # Filter the elements
    filtered_elements = [
        item for item, count in frequency_counter.items() if
        count > per_upper
    ]

    print(
        f"-- -- Keeping {len(filtered_elements)} elements out of {len(splits_list)}.")

    # Add additional manual elements and remove duplicates
    final_list = list(set(filtered_elements + MANUAL_STOPS))
    final_list.sort()
    print(f"-- -- Final list has {len(final_list)} elements.")

    # Save the list
    path_save = pathlib.Path("metalists/filtered_elements.txt")
    with open(path_save, 'w') as file:
        for item in final_list:
            file.write("%s\n" % item)


if __name__ == "__main__":
    main()
